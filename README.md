# Sign-Language-Recognition
In this project, we have created a model to detect sign language using mediapipe holistic keypoints and LSTM layered model.

Dumb people use hand signs to communicate, hence normal people face problem in recognizing their language by signs made.Hence there is a need of the systems which recognizes the different signs and conveys the
information to the normal people.

The aim of our project is to develop a concept of virtual talking system without sensor for
people who in need, this concept achieving a by using image processing and human hand
gesture input.This mainly helps to people who canâ€™t talk with other people.

Implementation steps are as follows:
Install and Import Dependencies

Detect Face,Hand and Pose Landmarks

Setup Folders for Data collection

Preprocess Data and Create Labels

Build and Train an LSTM Deep Learning Model

Make Sign Language Predictions

Save Model Weights

Evaluation using a Confusion Matrix

Test in Real Time
